{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸŒŒ LLM Thought Landscape Visualization\n",
    "**Understanding Reasoning Patterns in Large Language Models**  \n",
    "\n",
    "*Visual Diagnostics for Chain-of-Thought Reasoning*  [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1QzAw5bW6RO1v-Tb68dowj5562nN3Cv_c?usp=sharing)  \n",
    "\n",
    "\n",
    "\n",
    "![demo](./imgs/demo.png)\n",
    "\n",
    "---\n",
    "\n",
    "## Table of Contents\n",
    "1. [Background & Motivation](#1)\n",
    "2. [Data Preparation](#2)\n",
    "3. [Visualization](#3) \n",
    "Â Â Â "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"1\"></a>\n",
    "## 1. Background & Motivation\n",
    "\n",
    "### Why Thought Landscapes?\n",
    "Modern LLMs demonstrate impressive reasoning capabilities through techniques like chain-of-thought prompting, but their internal decision-making processes remain opaque. This notebook implements our novel visualization method that:\n",
    "\n",
    "1. **Maps reasoning paths** as 2D landscapes using semantic distance metrics\n",
    "2. **Identifies critical patterns**: \n",
    "   - Model capability boundaries\n",
    "   - Answer confidence levels\n",
    "   - Consistency between reasoning steps\n",
    "3. **Supports model diagnostics** through:\n",
    "   - Weak/Strong model differentiation\n",
    "   - Error cluster detection\n",
    "   - Uncertainty quantification\n",
    "\n",
    "**Key Innovation**: First method enabling direct visual comparison of different reasoning strategies (CoT, LeastToMost, ToT, and MCTS) across multiple choice questions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"2\"></a>\n",
    "## 2. Data Preparation\n",
    "\n",
    "We provide the exact same data used for visulizing the plot in our paper, you can use the following command to download the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git lfs clone git@hf.co:datasets/GazeEzio/Landscape-Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The expected file tree is:\n",
    "\n",
    "```\n",
    "Landscape-of-Thoughts/\n",
    "â”‚    ...\n",
    "â”œâ”€â”€  Landscape-Data/\n",
    "â”‚    â”œâ”€â”€ aqua\n",
    "â”‚    â”‚   â”œâ”€â”€ distance_matrix\n",
    "â”‚    â”‚   â””â”€â”€ thoughts\n",
    "â”‚    â””â”€â”€...\n",
    "â”‚   ...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from step_3_plot_landscape import draw\n",
    "from utils.visual_utils import *\n",
    "\n",
    "ROOT=\"./Landscape-Data\"\n",
    "MODEL=\"Meta-Llama-3.1-70B-Instruct-Turbo\"\n",
    "DATASET=\"aqua\"\n",
    "METHOD=\"cot\"\n",
    "TOTAL_SAMPLE=50\n",
    "SAMPLE_INDEX=1\n",
    "\n",
    "print(\"==> Loading data for single problem...\")\n",
    "(\n",
    "    coordinates_2d, num_thoughts_each_chain, num_chains, labels_anchors, \n",
    "    answer_gt_short, anchors_idx_x, num_all_thoughts\n",
    ") = process_single_thought_file(\n",
    "    thoughts_file=f'{ROOT}/{DATASET}/thoughts/{MODEL}--{METHOD}--{DATASET}--{SAMPLE_INDEX}.json', \n",
    ")\n",
    "\n",
    "print(\"==> Loading data for all the problems...\")\n",
    "list_all_T_2D, A_matrix_2D, list_plot_data, list_num_all_thoughts_w_start_list = process_data(\n",
    "    model='Meta-Llama-3.1-70B-Instruct-Turbo', \n",
    "    dataset='aqua', \n",
    "    plot_type='method',\n",
    "    total_sample=50,\n",
    "    ROOT=ROOT\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"3\"></a>\n",
    "## 3. Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot all the samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"==> Drawing...\")\n",
    "for plot_datas, splited_T_2D, num_all_thoughts_w_start_list in zip(list_plot_data, list_all_T_2D, list_num_all_thoughts_w_start_list):\n",
    "    fig = draw(\n",
    "        dataset_name='aqua', \n",
    "        plot_datas=plot_datas, splited_T_2D=splited_T_2D, A_matrix_2D=A_matrix_2D, num_all_thoughts_w_start_list=num_all_thoughts_w_start_list, \n",
    "    )\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot single sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"==> Drawing...\")\n",
    "fig = plot_chain_animation(num_chains, num_thoughts_each_chain, coordinates_2d, anchors_idx_x, labels_anchors, answer_gt_short)\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "post-training",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
