{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sGCBxbAJwk7d"
      },
      "source": [
        "# ðŸŒŒ LLM Thought Landscape Visualization\n",
        "**Understanding Reasoning Patterns in Large Language Models**  \n",
        "\n",
        "*Visual Diagnostics for Chain-of-Thought Reasoning*   \n",
        "\n",
        "[![github badge](https://camo.githubusercontent.com/cf783a33cd08f7ba7e9fb758137fc9ebd587f4d9119b93ba4f1933afa23406ec/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4769746875622d3138313731373f7374796c653d666c61742d737175617265266c6f676f3d676974687562266c6f676f436f6c6f723d7768697465)](https://github.com/tmlr-group/landscape-of-thoughts)\n",
        "\n",
        "\n",
        "\n",
        "<!-- ![demo](./imgs/demo.png) -->\n",
        "\n",
        "---\n",
        "\n",
        "## Table of Contents\n",
        "1. [**Background & Motivation**](#1)\n",
        "\n",
        "2. **Plot With Your Own Data**\n",
        "   \n",
        "   1.1 [Constructing Data](#2)\n",
        "\n",
        "   1.2 [Calculate the Data for Visualization](#3)\n",
        "   \n",
        "   1.3 [Visualize the Data](#4)\n",
        "\n",
        "3. **Reproduce the Plot in the Paper**\n",
        "   \n",
        "   3.1 [Data Preparation](#5)\n",
        "   \n",
        "   3.2 [Visualization](#6)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Clone the Repo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!git clone https://github.com/tmlr-group/landscape-of-thoughts\n",
        "%cd landscape-of-thoughts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NXNgCueswk7g"
      },
      "source": [
        "<a id=\"1\"></a>\n",
        "## Background & Motivation\n",
        "\n",
        "### Why Thought Landscapes?\n",
        "Modern LLMs demonstrate impressive reasoning capabilities through techniques like chain-of-thought prompting, but their internal decision-making processes remain opaque. This notebook implements our novel visualization method that:\n",
        "\n",
        "1. **Maps reasoning paths** as 2D landscapes using semantic distance metrics\n",
        "2. **Identifies critical patterns**:\n",
        "   - Model capability boundaries\n",
        "   - Answer confidence levels\n",
        "   - Consistency between reasoning steps\n",
        "3. **Supports model diagnostics** through:\n",
        "   - Weak/Strong model differentiation\n",
        "   - Error cluster detection\n",
        "   - Uncertainty quantification\n",
        "\n",
        "**Key Innovation**: First method enabling direct visual comparison of different reasoning strategies (CoT, LeastToMost, ToT, and MCTS) across multiple choice questions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fvbJ-oQtzQYY"
      },
      "source": [
        "## 1. Plot With You Own Data\n",
        "\n",
        "<a id=\"2\"></a>\n",
        "### 1.1 Constructing Data\n",
        "\n",
        "Format your data as follows, an example can be found in `lot/data/dummy.jsonl`:\n",
        "```json\n",
        "{\n",
        "    \"question\": \"20 marbles were pulled out of a bag of only white marbles, painted black, and then put back in. Then, another 20 marbles were pulled out, of which 1 was black, after which they were all returned to the bag. If the percentage of black marbles pulled out the second time represents their percentage in the bag, how many marbles in total Q does the bag currently hold?\",\n",
        "    \"options\": [\n",
        "        \"A)40\",\n",
        "        \"B)200\",\n",
        "        \"C)380\",\n",
        "        \"D)400\",\n",
        "        \"E)3200\"\n",
        "    ],\n",
        "    \"correct\": \"D\"\n",
        "}\n",
        "```\n",
        "\n",
        "You can use the following code to load the data and format the prompt."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from lot.datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(\n",
        "    dataset_name=\"dummy\", \n",
        "    data_path=\"lot/data/dummy.jsonl\",\n",
        "    answer_field=\"correct\",\n",
        "    options_field=\"options\",\n",
        "    question_field=\"question\"\n",
        ")\n",
        "\n",
        "question = dataset.get_query(0)\n",
        "answer = dataset.get_answer(0)\n",
        "prompt = dataset.format_prompt(idx=0, method=\"cot\")\n",
        "print(\"Question: \", question)\n",
        "print(\"Answer: \", answer)\n",
        "print(\"Prompt: \", prompt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id=\"3\"></a>\n",
        "### 1.2 Calculate the Data for Visualization\n",
        "\n",
        "You can use the following code to calculate the data for visualization. You need to setup LLM first, either local (vLLM) or remote (Together.ai). Check [setup_model.md](doc/setup_model.md) for more details.\n",
        "\n",
        "\n",
        "In this example, we use the remote LLM (Together.ai), using `Meta-Llama-3-8B-Instruct-Lite`, `CoT` method and `dummy` dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from lot import sample, calculate\n",
        "import os \n",
        "os.environ[\"TOGETHERAI_API_KEY\"] = \"YOUR KEY HERE\"\n",
        "# Sample reasoning traces\n",
        "features, metrics = sample(\n",
        "    model_name=\"meta-llama/Meta-Llama-3-8B-Instruct-Lite\",\n",
        "    dataset_name=\"dummy\",\n",
        "    data_path=\"lot/data/dummy.jsonl\",\n",
        "    method=\"cot\",\n",
        "    num_samples=10,\n",
        "    start_index=0,\n",
        "    end_index=5,\n",
        "    save_root=\"./exp-data\"\n",
        ")\n",
        "\n",
        "# Calculate distance matrices\n",
        "distance_matrices = calculate(\n",
        "    model_name=\"meta-llama/Meta-Llama-3-8B-Instruct-Lite\",\n",
        "    dataset_name=\"dummy\",\n",
        "    data_path=\"lot/data/dummy.jsonl\",\n",
        "    method=\"cot\",\n",
        "    start_index=0,\n",
        "    end_index=5,\n",
        "    save_root=\"./exp-data\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id=\"4\"></a>\n",
        "### 1.3 Visualize the Data\n",
        "\n",
        "You can use the following code to calculate the data for visualization."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from lot import plot\n",
        "\n",
        "plot(\n",
        "    model_name=\"Meta-Llama-3-8B-Instruct-Lite\",\n",
        "    dataset_name=\"dummy\",\n",
        "    method=\"cot\",\n",
        "    save_root=\"./exp-data\",\n",
        "    output_dir=\"figures/landscape\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YMmw46l2zDQy"
      },
      "source": [
        "## 2. Reproduce the Plot in the Paper\n",
        "<a id=\"5\"></a>\n",
        "### 2.1 Data Preparation\n",
        "\n",
        "We provide the exact same data used for visulizing the plot in our paper, you can use the following command to download the data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-6nkvsmEwk7h"
      },
      "outputs": [],
      "source": [
        "!git lfs clone git@hf.co:datasets/GazeEzio/Landscape-Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Rq7j_2nwk7i"
      },
      "source": [
        "The expected file tree is:\n",
        "\n",
        "```\n",
        "Landscape-of-Thoughts/\n",
        "â”‚    ...\n",
        "â”œâ”€â”€  Landscape-Data/\n",
        "â”‚    â”œâ”€â”€ aqua\n",
        "â”‚    â”‚   â”œâ”€â”€ distance_matrix\n",
        "â”‚    â”‚   â””â”€â”€ thoughts\n",
        "â”‚    â””â”€â”€...\n",
        "â”‚   ...\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jKc5TZrPwk7i"
      },
      "outputs": [],
      "source": [
        "from step_3_plot_landscape import draw\n",
        "from utils.visual_utils import *\n",
        "ROOT=\"./Landscape-Data\"\n",
        "\n",
        "print(\"==> Loading data...\")\n",
        "\n",
        "list_all_T_2D, A_matrix_2D, list_plot_data, list_num_all_thoughts_w_start_list = process_data(\n",
        "    model='Meta-Llama-3.1-70B-Instruct-Turbo',\n",
        "    dataset='aqua',\n",
        "    plot_type='method',\n",
        "    total_sample=50,\n",
        "    ROOT=ROOT\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WMhugKFjwk7j"
      },
      "source": [
        "<a id=\"6\"></a>\n",
        "### 2.2 Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xpGV6GHdwk7j"
      },
      "outputs": [],
      "source": [
        "print(\"==> Drawing...\")\n",
        "for plot_datas, splited_T_2D, num_all_thoughts_w_start_list in zip(list_plot_data, list_all_T_2D, list_num_all_thoughts_w_start_list):\n",
        "    fig = draw(\n",
        "        dataset_name='aqua',\n",
        "        plot_datas=plot_datas, splited_T_2D=splited_T_2D, A_matrix_2D=A_matrix_2D, num_all_thoughts_w_start_list=num_all_thoughts_w_start_list,\n",
        "    )\n",
        "    fig.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "post-training",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.15"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
